# -*- coding: utf-8 -*-
import os
import sys
import time
from google import genai
from google.genai.errors import APIError

# å¼ºåˆ¶ç¯å¢ƒä½¿ç”¨ UTF-8 ç¼–ç 
sys.stdout.reconfigure(encoding='utf-8')
sys.stderr.reconfigure(encoding='utf-8')

# ----------------------------------------------------
# ğŸ¯ ä»£ç†å’Œæ–‡ä»¶é…ç½®
# ----------------------------------------------------
proxy_address = "127.0.0.1:7897"
os.environ['http_proxy'] = f"http://{proxy_address}"
os.environ['https_proxy'] = f"http://{proxy_address}"

# è¾“å…¥æ–‡ä»¶
TRANSCRIPT_FILE = "AI_is_coming_for_your_job._Now_what_transcript.txt"
PROMPT_FILE = "prompt.md"
# è¾“å‡ºæ–‡ä»¶
OUTPUT_MD_FILE = "analysis_result.md"


def load_file_content(filepath):
    if not os.path.exists(filepath):
        print(f"âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°æ–‡ä»¶ -> {filepath}")
        return None
    with open(filepath, 'r', encoding='utf-8') as f:
        return f.read()


def get_api_key_interactively():
    print("-" * 60)
    api_key = input("ğŸ”‘ è¯·è¾“å…¥æ‚¨çš„ Gemini API Keyï¼š\n> ")
    print("-" * 60)
    return api_key.strip()


def analyze_and_save():
    print("=" * 60)
    print(f"ğŸŒ ä»£ç†çŠ¶æ€: {proxy_address}")

    # 1. åŠ è½½æŒ‡ä»¤
    analysis_prompt = load_file_content(PROMPT_FILE)
    if not analysis_prompt: return

    # 2. è·å– API Key
    gemini_api_key = get_api_key_interactively()
    if not gemini_api_key: return

    # 3. åˆå§‹åŒ–å®¢æˆ·ç«¯
    model_name = 'gemini-2.5-flash'
    client = genai.Client(api_key=gemini_api_key)
    uploaded_file = None

    try:
        # 4. ä½¿ç”¨ File API ä¸Šä¼ å¤§æ–‡æœ¬
        print(f"â¬†ï¸ æ­£åœ¨ä¸Šä¼ è½¬å½•æ–‡æœ¬...")
        start_upload = time.time()

        # *** ä¿®å¤ç‚¹ï¼šå°† path= æ”¹ä¸º file= ***
        uploaded_file = client.files.upload(file=TRANSCRIPT_FILE)

        print(f"âœ… ä¸Šä¼ æˆåŠŸ (è€—æ—¶: {time.time() - start_upload:.2f}s)")

        # 5. è°ƒç”¨æ¨¡å‹ (åå°æµå¼è·å–ï¼Œé˜²æ­¢è¿æ¥ä¸­æ–­)
        print(f"ğŸš€ Gemini æ­£åœ¨æ·±åº¦åˆ†æä¸­ï¼Œè¯·ç¨å€™...")

        response_stream = client.models.generate_content_stream(
            model=model_name,
            contents=[analysis_prompt, uploaded_file]
        )

        full_content = ""
        # å³ä½¿ä¸æ‰“å°ï¼Œä¹Ÿé€šè¿‡è¿­ä»£æµæ¥ä¿æŒè¿æ¥æ´»è·ƒ
        for chunk in response_stream:
            if chunk.text:
                full_content += chunk.text
                # æ‰“å°ä¸€ä¸ªç‚¹è¡¨ç¤ºè¿›åº¦ï¼Œé¿å…ç•Œé¢çœ‹èµ·æ¥åƒå¡ä½äº†
                print(".", end="", flush=True)

        print("\n" + "-" * 60)

        # 6. ä¿å­˜ä¸º Markdown æ–‡ä»¶
        with open(OUTPUT_MD_FILE, "w", encoding="utf-8") as md_file:
            md_file.write(f"# Gemini åˆ†ææŠ¥å‘Š\n\n")
            md_file.write(f"- **åˆ†ææ—¶é—´**: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
            md_file.write(f"- **æºæ–‡ä»¶**: {TRANSCRIPT_FILE}\n\n---\n\n")
            md_file.write(full_content)

        print(f"ğŸ‰ åˆ†æå®Œæˆå¹¶å·²ä¿å­˜ï¼")
        print(f"ğŸ“„ ç»“æœæ–‡ä»¶: {OUTPUT_MD_FILE}")
        print("-" * 60)

    except Exception as e:
        print(f"\nâŒ å¤„ç†å¤±è´¥: {e}")

    finally:
        # 7. æ¸…ç†äº‘ç«¯ä¸´æ—¶æ–‡ä»¶
        if uploaded_file:
            try:
                client.files.delete(name=uploaded_file.name)
                print("âœ¨ äº‘ç«¯ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†ã€‚")
            except:
                pass


if __name__ == "__main__":
    analyze_and_save()